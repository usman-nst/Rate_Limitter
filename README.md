# ğŸš¦ Express Rate Limiting with Redis (In-Memory vs Distributed)

This project showcases how to implement **rate limiting** in an Express.js API using two approaches:

- âœ… **In-Memory Rate Limiting** â€“ Simple and lightweight, but limited to a single server instance.
- âš¡ **Redis-Backed Rate Limiting** â€“ Scalable and ideal for distributed or multi-instance environments.

---

## ğŸ§  What is Rate Limiting?

**Rate limiting** restricts the number of requests a user can make to your API within a specific time window. Itâ€™s essential for securing and optimizing your application.

ğŸ”’ It protects against:
- Abuse (e.g., brute force attacks)
- Endpoint spamming
- Server overload

---

## ğŸ’¥ The Problem with In-Memory Rate Limiting

By default, `express-rate-limit` stores request counters **in memory**. This works for a single server but fails in distributed setups:

```bash
User 1 â†’ Server A â†’ Request count stored in Server A's memory  
User 1 â†’ Server B â†’ Request count stored separately in Server B's memory  
```

Since each server maintains its own counter, the rate limit isnâ€™t enforced consistently across instances.  
âŒ Users could bypass limits by hitting different servers.  
âŒ No shared state = unreliable limits in real-world deployments.

---

## ğŸ› ï¸ The Solution: Redis-Backed Rate Limiting

Using Redis with `rate-limit-redis`, you can centrally store rate limit counters. This ensures consistent enforcement across all servers:

âœ… Shared counter  
âœ… Works in load-balanced environments  
âœ… More production-ready and scalable

---

## ğŸ”§ Prerequisites

- Node.js
- Docker (for Redis setup)

---

## ğŸ“¦ Install Dependencies

```bash
npm install express express-rate-limit rate-limit-redis ioredis
```

---

## ğŸš€ Run Redis Using Docker

```bash
docker run -d --name redis-rate-limit -p 6379:6379 redis
```

---

## ğŸ§ª Usage Examples

### 1. In-Memory Limiting

```js
const rateLimit = require('express-rate-limit');

const limiter = rateLimit({
  windowMs: 1 * 60 * 1000, // 1 minute
  max: 5, // limit each IP to 5 requests per windowMs
});

app.use('/api', limiter);
```

---

### 2. Redis-Backed Limiting (Distributed)

```js
const rateLimit = require('express-rate-limit');
const RedisStore = require('rate-limit-redis');
const Redis = require('ioredis');

const redisClient = new Redis({
  host: 'localhost',
  port: 6379,
});

const limiter = rateLimit({
  store: new RedisStore({
    sendCommand: (...args) => redisClient.call(...args),
  }),
  windowMs: 1 * 60 * 1000, // 1 minute
  max: 5,
});

app.use('/api', limiter);
```

---

## ğŸ§ª Testing the Limit

Start the server, and try to hit `/api` more than 5 times within a minute.  
You'll see a 429 `Too Many Requests` response.

Try the same using multiple instances (load balancer simulation) and:

âœ… Redis will enforce the limit globally  
âŒ In-memory will enforce it per process

---

## ğŸ“ Conclusion

| Approach    | Pros                  | Cons                            |
|------------|-----------------------|---------------------------------|
| In-Memory  | Simple to use         | Not suitable for multi-instance setups |
| Redis-Based| Scalable and consistent| Requires Redis setup            |

For **real-world production apps**, always prefer **Redis-backed rate limiting**.

---

## ğŸ“ Project Structure

```
ğŸ“¦ express-rate-limit-demo/
â”œâ”€â”€ in-memory.js        # In-memory rate limiting example
â”œâ”€â”€ redis-limit.js      # Redis-backed rate limiting example
â”œâ”€â”€ Dockerfile (optional if needed)
â””â”€â”€ README.md
```

---
